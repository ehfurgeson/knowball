{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFL\n",
    "\n",
    "Predicting overall fantasy points throughout the season based on pre-season performance\n",
    "\n",
    "Predicting fantasy points at the end of a game based on performance at any given amount of minutes into the game\n",
    "\n",
    "(both of these predictions should be done separetely for each position)\n",
    "\n",
    "First I will try to just make these simple multiple regression problems and see how accurate I can get with that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Plans\n",
    "\n",
    "## Possible Data Sources\n",
    "\n",
    "**Free/Accessible APIs:**\n",
    "- **ESPN Fantasy API**: Player projections, ownership percentages, scoring\n",
    "- **NFL API**: Official game stats, injury reports, weather\n",
    "- **Pro Football Reference**: Historical stats (can be scraped respectfully)\n",
    "- **FantasyPros**: Expert consensus rankings, start/sit advice APIs\n",
    "- **Weather APIs**: Weather Underground, OpenWeatherMap for game conditions\n",
    "- **DraftKings/FanDuel**: Salary data and ownership percentages (where available)\n",
    "- **Reddit Fantasy Football**: Sentiment analysis from r/fantasyfootball discussions\n",
    "\n",
    "**Premium but Worth It:**\n",
    "- **Fantasy Football Data Co**: Clean, comprehensive APIs\n",
    "- **Pro Football Focus (PFF)**: Advanced metrics (subscription required)\n",
    "- **Sports Info Solutions**: Detailed player tracking data\n",
    "\n",
    "## Project Steps to Execute\n",
    "\n",
    "### 1. Problem Definition and Scope\n",
    "Define exactly what you want to predict: weekly player performance, start/sit decisions, waiver wire pickups, trade values, or season-long projections. Decide whether you're focusing on redraft leagues, dynasty, DFS, or all formats. Choose your success metrics - are you trying to beat expert consensus, maximize points, or minimize risk?\n",
    "\n",
    "### 2. Data Collection Strategy\n",
    "Start with one primary data source and expand gradually. Build robust data collection scripts that can handle API rate limits and failures gracefully. Focus on getting consistent data for current season first, then add historical data. Plan for weekly automated updates throughout the season.\n",
    "\n",
    "### 3. Feature Engineering Deep Dive\n",
    "Create meaningful predictive features beyond basic stats. Consider target share trends, red zone touches, snap counts, defensive matchup ratings, weather impact factors, and injury risk indicators. Engineer rolling averages, recent form metrics, and situational statistics (home/away, primetime games, etc.).\n",
    "\n",
    "### 4. Model Development Approach\n",
    "Start with simple baselines like expert consensus or previous week performance. Try multiple approaches: regression for point prediction, classification for boom/bust probability, ensemble methods combining multiple models. Consider position-specific models since QB, RB, WR, and TE have different predictive patterns.\n",
    "\n",
    "### 5. Validation Strategy\n",
    "Use proper time series validation - don't use future data to predict the past. Test on holdout seasons, not just random samples. Compare against expert rankings and simple baselines. Track both accuracy and practical value (would following your advice actually improve fantasy teams?).\n",
    "\n",
    "### 6. Dashboard/Sharing Platform Design\n",
    "Build something people will actually use weekly. Consider automated weekly reports, sleeper alerts for breakout candidates, injury impact analysis, and trade value assessments. Make it mobile-friendly since fantasy managers check constantly. Include confidence intervals, not just point predictions.\n",
    "\n",
    "### 7. Automation and Maintenance\n",
    "Plan for weekly data updates throughout the season. Build monitoring to catch when APIs change or data sources fail. Consider how to handle bye weeks, injuries, and trade deadline chaos. Set up automated model retraining as new data comes in.\n",
    "\n",
    "## Specific Project Ideas\n",
    "\n",
    "**\"The Waiver Wire Prophet\"**\n",
    "- Predict which available players (< 50% owned) will have breakout weeks\n",
    "- Focus on actionable insights for players people can actually pick up\n",
    "- Weekly newsletter with top waiver targets and reasoning\n",
    "\n",
    "**\"Matchup Exploiter\"**\n",
    "- Predict which players will outperform expectations based on defensive matchups\n",
    "- Combine player trends with opponent weaknesses\n",
    "- Weekly start/sit recommendations with confidence levels\n",
    "\n",
    "**\"Injury Impact Analyzer\"**\n",
    "- Predict how injuries affect both the injured player and teammates\n",
    "- Real-time updates when injury news breaks\n",
    "- Target players who benefit from others' injuries\n",
    "\n",
    "**\"Weather Game Predictor\"**\n",
    "- Focus specifically on how weather affects player performance\n",
    "- Particularly valuable for outdoor games in winter\n",
    "- Simple, focused tool that does one thing really well\n",
    "\n",
    "\n",
    "\n",
    "## Technical Considerations\n",
    "\n",
    "**Start simple**: Get basic player stat prediction working before adding complex features\n",
    "\n",
    "**Focus on actionable predictions**: \"Player X will score 15.3 points\" is less useful than \"Player X has 70% chance to outscore his projection\"\n",
    "\n",
    "**Handle missing data gracefully**: Injuries, snap count changes, and weather delays happen constantly\n",
    "\n",
    "**Build for weekly cycles**: Fantasy football is inherently weekly - design around that rhythm\n",
    "\n",
    "The key is starting with one focused prediction problem, proving it works, then expanding. Most successful fantasy tools do one thing really well rather than trying to predict everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GNN with edge weights? Edge weights based on teammate \"cohesion\"? Don't know if either of those are possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a model that can analyze 3D pivot point structure of a human body based on video, then utilize that to predict what kind of biomechanical moves result in better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape individual player data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_data(year):\n",
    "    url = f'https://www.pro-football-reference.com/years/{year}/fantasy.htm'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table and convert it to a DataFrame\n",
    "    table = soup.find('table', {'id': 'fantasy'})\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "\n",
    "    # Clean the DataFrame (remove multi-level headers, etc.)\n",
    "    df.columns = df.columns.droplevel(0)  # Drop the first header level\n",
    "    df = df.rename(columns={'Unnamed: 0_level_1': 'Player'})  # Rename player column\n",
    "    df = df[df['Player'] != 'Player']  # Remove extra header rows\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get player data for the 2023 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\elifu\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\elifu\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'html5lib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m player_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_player_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mscrape_player_data\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Find the table and convert it to a DataFrame\u001b[39;00m\n\u001b[0;32m      7\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfantasy\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStringIO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Clean the DataFrame (remove multi-level headers, etc.)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdroplevel(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Drop the first header level\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elifu\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1245\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1230\u001b[0m     [\n\u001b[0;32m   1231\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     ]\n\u001b[0;32m   1236\u001b[0m ):\n\u001b[0;32m   1237\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1242\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1243\u001b[0m     )\n\u001b[1;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elifu\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:976\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m retained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[1;32m--> 976\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[43m_parser_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflav\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m     p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    978\u001b[0m         io,\n\u001b[0;32m    979\u001b[0m         compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    984\u001b[0m         storage_options,\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\elifu\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:920\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(flavor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid flavor, valid flavors are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_parsers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbs4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml5lib\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 920\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml5lib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbs4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\elifu\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib."
     ]
    }
   ],
   "source": [
    "player_df = scrape_player_data(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rk                 Player   Tm FantPos Age   G  GS  Cmp  Att   Yds  ...  TD  \\\n",
      "0  1  Christian McCaffrey*+  SFO      RB  27  16  16    0    0     0  ...  21   \n",
      "1  2          CeeDee Lamb*+  DAL      WR  24  17  17    0    0     0  ...  14   \n",
      "2  3             Josh Allen  BUF      QB  27  17  17  385  579  4306  ...  15   \n",
      "3  4          Tyreek Hill*+  MIA      WR  29  16  16    0    0     0  ...  13   \n",
      "4  5           Jalen Hurts*  PHI      QB  25  17  17  352  538  3858  ...  15   \n",
      "\n",
      "   2PM  2PP FantPt    PPR   DKPt   FDPt  VBD PosRank OvRank  \n",
      "0  NaN  NaN    324  391.3  399.3  357.8  157       1      1  \n",
      "1    1  NaN    268  403.2  411.2  335.7  131       1      2  \n",
      "2  NaN    3    393  392.6  420.6  410.6  122       1      3  \n",
      "3  NaN  NaN    257  376.4  380.4  316.9  120       2      4  \n",
      "4  NaN  NaN    357  356.8  382.8  371.8   89       2      5  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Index(['Rk', 'Player', 'Tm', 'FantPos', 'Age', 'G', 'GS', 'Cmp', 'Att', 'Yds',\n",
      "       'TD', 'Int', 'Att', 'Yds', 'Y/A', 'TD', 'Tgt', 'Rec', 'Yds', 'Y/R',\n",
      "       'TD', 'Fmb', 'FL', 'TD', '2PM', '2PP', 'FantPt', 'PPR', 'DKPt', 'FDPt',\n",
      "       'VBD', 'PosRank', 'OvRank'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(player_df.head())\n",
    "\n",
    "# Display the variable names of the DataFrame\n",
    "print(player_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data to ensure it's suitable for regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the DataFrame (remove unnecessary columns, handle missing values, etc.)\n",
    "# player_df = player_df[['Player', 'Tm', 'FantPos', 'G', 'Cmp', 'Att', 'Yds', 'TD', 'Int', 'Att', 'Yds', 'TD', 'Tgt', 'Rec', 'Yds', 'TD', 'FantPt']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "new_names = ({'Tm': 'Team', 'FantPos': 'Position', 'G': 'Games', \n",
    "                                       'Cmp': 'PassingCompletions', 'Att': 'PassingAttempts', 'Yds': 'PassingYards', \n",
    "                                       'TD': 'PassingTD', 'Int': 'PassingInt', 'Att': 'RushingAttempts', \n",
    "                                       'Yds': 'RushingYards', 'TD': 'RushingTD', 'Tgt': 'ReceivingTargets', \n",
    "                                       'Rec': 'Receptions', 'Yds': 'ReceivingYards', 'TD': 'ReceivingTD', \n",
    "                                       'FantPt': 'FantasyPoints'\n",
    "                                       })\n",
    "# player_df = player_df.rename(columns = new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that passes in a dataframe to give each player a unique identifier\n",
    "def create_player_id(df):\n",
    "    # remove * and + from player names\n",
    "    df['PlayerID'] = df['Player'].str.replace('*', '')\n",
    "    df['PlayerID'] = df['PlayerID'].str.replace('+', '')\n",
    "    df['PlayerID'] = df['PlayerID'].str.split('\\\\').str[0]  # Remove special characters\n",
    "    df['PlayerID'] = df['PlayerID'].str.lower()  # Convert to lowercase\n",
    "    df['PlayerID'] = df['PlayerID'] + df.groupby('PlayerID').cumcount().astype(str)  # Add a count to handle duplicates\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Player', 'Team', 'Position', 'Games', 'PassingCompletions',\n",
      "       'RushingAttempts', 'RushingAttempts', 'ReceivingYards',\n",
      "       'ReceivingYards', 'ReceivingYards', 'ReceivingTD', 'ReceivingTD',\n",
      "       'ReceivingTD', 'ReceivingTD', 'PassingInt', 'RushingAttempts',\n",
      "       'RushingAttempts', 'ReceivingYards', 'ReceivingYards', 'ReceivingYards',\n",
      "       'ReceivingTD', 'ReceivingTD', 'ReceivingTD', 'ReceivingTD',\n",
      "       'ReceivingTargets', 'Receptions', 'ReceivingYards', 'ReceivingYards',\n",
      "       'ReceivingYards', 'ReceivingTD', 'ReceivingTD', 'ReceivingTD',\n",
      "       'ReceivingTD', 'FantasyPoints'],\n",
      "      dtype='object')\n",
      "                    Player              PlayerID\n",
      "0    Christian McCaffrey*+  christian mccaffrey0\n",
      "1            CeeDee Lamb*+          ceedee lamb0\n",
      "2               Josh Allen           josh allen0\n",
      "3            Tyreek Hill*+          tyreek hill0\n",
      "4             Jalen Hurts*          jalen hurts0\n",
      "..                     ...                   ...\n",
      "647             Kyle Allen           kyle allen0\n",
      "648           Deon Jackson         deon jackson0\n",
      "650            David Wells          david wells0\n",
      "651           James Proche         james proche0\n",
      "652           Trent Taylor         trent taylor0\n",
      "\n",
      "[632 rows x 2 columns]\n",
      "                  Player Team Position  Games  PassingCompletions  \\\n",
      "0  Christian McCaffrey*+  SFO       RB     16                   0   \n",
      "1          CeeDee Lamb*+  DAL       WR     17                   0   \n",
      "2             Josh Allen  BUF       QB     17                 385   \n",
      "3          Tyreek Hill*+  MIA       WR     16                   0   \n",
      "4           Jalen Hurts*  PHI       QB     17                 352   \n",
      "\n",
      "   RushingAttempts  RushingAttempts  ReceivingYards  ReceivingYards  \\\n",
      "0                0              272               0            1459   \n",
      "1                0               14               0             113   \n",
      "2              579              111            4306             524   \n",
      "3                0                6               0              15   \n",
      "4              538              157            3858             605   \n",
      "\n",
      "   ReceivingYards  ...  Receptions  ReceivingYards  ReceivingYards  \\\n",
      "0             564  ...          67               0            1459   \n",
      "1            1749  ...         135               0             113   \n",
      "2               0  ...           0            4306             524   \n",
      "3            1799  ...         119               0              15   \n",
      "4               0  ...           0            3858             605   \n",
      "\n",
      "   ReceivingYards  ReceivingTD  ReceivingTD  ReceivingTD  ReceivingTD  \\\n",
      "0             564            0           14            7           21   \n",
      "1            1749            0            2           12           14   \n",
      "2               0           29           15            0           15   \n",
      "3            1799            0            0           13           13   \n",
      "4               0           23           15            0           15   \n",
      "\n",
      "   FantasyPoints              PlayerID  \n",
      "0          324.0  christian mccaffrey0  \n",
      "1          268.0          ceedee lamb0  \n",
      "2          393.0           josh allen0  \n",
      "3          257.0          tyreek hill0  \n",
      "4          357.0          jalen hurts0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elifu\\AppData\\Local\\Temp\\ipykernel_4328\\3598492347.py:21: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  player_df = player_df.apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the player DataFrame\n",
    "player_df = create_player_id(player_df)\n",
    "\n",
    "# Display the new player ID column\n",
    "print(player_df[['Player', 'PlayerID']])\n",
    "\n",
    "# Convert columns to appropriate data types\n",
    "player_df = player_df.apply(pd.to_numeric, errors='ignore')\n",
    "player_df['FantasyPoints'] = player_df['FantasyPoints'].astype(float)\n",
    "\n",
    "# Handle missing values (e.g., fill with 0 or use appropriate imputation method)\n",
    "player_df = player_df.fillna(0)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(player_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the current DataFrame as a CSV file\n",
    "# player_df.to_csv('player_data_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I attempted many times to find a good way to scrape lots of preseason data on individual player performance\n",
    "\n",
    "Eventually I did find some good sources, however at that point I realized that even with good data the model to predict fantasy points througout the season using preseason performance just wouldn't be great because preseason games are so different from in season games, and the players that play in the preseason often get far less play in the actual season, therefore the predictions would likely underestimate performance for the players that do play a lot in both because it would be dragged down by players who play in the preseason but not in the regular season\n",
    "\n",
    "So, instead I am going to shift my focus to creating visualizations of player fantasy points given their performance at a given time in the game, and their average fantasy points for this season and the previous seasons\n",
    "\n",
    "My idea is to do this very simply by taking current fantasy points at x minutes into the game and then multiplying that by (total minutes in the game)/x then slightly altering that expectation by using the average fantasy points for this or last season to either drag up or down the prediction, this will effectively create a very simple time series forecast for the player's fantasy points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series forecasting for fantasy football points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the PlayerID, FantasyPoints, Games, and Position columns from the CSV file\n",
    "player_df = pd.read_csv('player_data_2023.csv', usecols=['PlayerID', 'FantasyPoints', 'Games', 'Position'])\n",
    "\n",
    "# Create a new column for average fantasy points per game\n",
    "player_df['AvgFPPG'] = player_df['FantasyPoints'] / player_df['Games']\n",
    "\n",
    "# Sort the DataFrame by average fantasy points per game in descending order\n",
    "player_df = player_df.sort_values(by='AvgFPPG', ascending=False)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(player_df.head())\n",
    "\n",
    "# Store the updated DataFrame as a CSV file\n",
    "player_df.to_csv('AvgFPPG_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position  Games  FantasyPoints        PlayerID    AvgFPPG\n",
      "0       QB     17          393.0     josh allen0  23.117647\n",
      "1       QB     17          357.0    jalen hurts0  21.000000\n",
      "2       QB     16          331.0  lamar jackson0  20.687500\n",
      "4       QB      5          101.0     joe flacco0  20.200000\n",
      "5       QB     17          343.0   dak prescott0  20.176471\n",
      "   Position  Games  FantasyPoints              PlayerID    AvgFPPG\n",
      "3        RB     16          324.0  christian mccaffrey0  20.250000\n",
      "8        RB     12          223.0       kyren williams0  18.583333\n",
      "20       RB     15          243.0       raheem mostert0  16.200000\n",
      "29       RB     11          164.0        de'von achane0  14.909091\n",
      "34       RB     10          137.0      jonathan taylor0  13.700000\n",
      "   Position  Games  FantasyPoints            PlayerID    AvgFPPG\n",
      "22       WR     16          257.0        tyreek hill0  16.062500\n",
      "25       WR     17          268.0        ceedee lamb0  15.764706\n",
      "39       WR     10          134.0   justin jefferson0  13.400000\n",
      "40       WR     16          212.0  amon-ra st. brown0  13.250000\n",
      "43       WR     13          171.0       keenan allen0  13.153846\n",
      "    Position  Games  FantasyPoints         PlayerID   AvgFPPG\n",
      "104       TE     17          153.0     sam laporta0  9.000000\n",
      "105       TE     10           90.0    mark andrews0  9.000000\n",
      "111       TE     16          138.0   george kittle0  8.625000\n",
      "115       TE     15          126.0    travis kelce0  8.400000\n",
      "117       TE     15          124.0  t.j. hockenson0  8.266667\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a new DataFrame\n",
    "player_df = pd.read_csv('AvgFPPG.csv')\n",
    "\n",
    "# Create a DataFrame for each position\n",
    "qb_df = player_df[player_df['Position'] == 'QB']\n",
    "rb_df = player_df[player_df['Position'] == 'RB']\n",
    "wr_df = player_df[player_df['Position'] == 'WR']\n",
    "te_df = player_df[player_df['Position'] == 'TE']\n",
    "\n",
    "# Display the first few rows of each position DataFrame\n",
    "print(qb_df.head())\n",
    "print(rb_df.head())\n",
    "print(wr_df.head())\n",
    "print(te_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeating the same several steps for 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data for 2022\n",
    "player_df_2022 = scrape_player_data(2022)\n",
    "\n",
    "# Clean the DataFrame (remove unnecessary columns, handle missing values, etc.)\n",
    "player_df_2022 = player_df_2022[['Player', 'Tm', 'FantPos', 'G', 'Cmp', 'Att', 'Yds', 'TD', 'Int', 'Att', 'Yds', 'TD', 'Tgt', 'Rec', 'Yds', 'TD', 'FantPt']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "player_df_2022 = player_df_2022.rename(columns = new_names)\n",
    "\n",
    "# Apply the function to the player DataFrame\n",
    "player_df_2022 = create_player_id(player_df_2022)\n",
    "\n",
    "# Convert columns to appropriate data types\n",
    "player_df_2022 = player_df_2022.apply(pd.to_numeric, errors='ignore')\n",
    "player_df_2022['FantasyPoints'] = player_df_2022['FantasyPoints'].astype(float)\n",
    "\n",
    "# Handle missing values (e.g., fill with 0 or use appropriate imputation method)\n",
    "player_df_2022 = player_df_2022.fillna(0)\n",
    "\n",
    "# Store the current DataFrame as a CSV file\n",
    "player_df_2022.to_csv('player_data_2022.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Position  Games  FantasyPoints              PlayerID    AvgFPPG\n",
      "2         QB     17          393.0           josh allen0  23.117647\n",
      "4         QB     17          357.0          jalen hurts0  21.000000\n",
      "9         QB     16          331.0        lamar jackson0  20.687500\n",
      "0         RB     16          324.0  christian mccaffrey0  20.250000\n",
      "126       QB      5          101.0           joe flacco0  20.200000\n"
     ]
    }
   ],
   "source": [
    "# Read the PlayerID, FantasyPoints, Games, and Position columns from the CSV file\n",
    "player_df = pd.read_csv('player_data_2023.csv', usecols=['PlayerID', 'FantasyPoints', 'Games', 'Position'])\n",
    "\n",
    "# Create a new column for average fantasy points per game\n",
    "player_df['AvgFPPG'] = player_df['FantasyPoints'] / player_df['Games']\n",
    "\n",
    "# Sort the DataFrame by average fantasy points per game in descending order\n",
    "player_df = player_df.sort_values(by='AvgFPPG', ascending=False)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(player_df.head())\n",
    "\n",
    "# Store the updated DataFrame as a CSV file\n",
    "player_df.to_csv('AvgFPPG_2022.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position  Games  FantasyPoints        PlayerID    AvgFPPG\n",
      "0       QB     17          393.0     josh allen0  23.117647\n",
      "1       QB     17          357.0    jalen hurts0  21.000000\n",
      "2       QB     16          331.0  lamar jackson0  20.687500\n",
      "4       QB      5          101.0     joe flacco0  20.200000\n",
      "5       QB     17          343.0   dak prescott0  20.176471\n",
      "   Position  Games  FantasyPoints              PlayerID    AvgFPPG\n",
      "3        RB     16          324.0  christian mccaffrey0  20.250000\n",
      "8        RB     12          223.0       kyren williams0  18.583333\n",
      "20       RB     15          243.0       raheem mostert0  16.200000\n",
      "29       RB     11          164.0        de'von achane0  14.909091\n",
      "34       RB     10          137.0      jonathan taylor0  13.700000\n",
      "   Position  Games  FantasyPoints            PlayerID    AvgFPPG\n",
      "22       WR     16          257.0        tyreek hill0  16.062500\n",
      "25       WR     17          268.0        ceedee lamb0  15.764706\n",
      "39       WR     10          134.0   justin jefferson0  13.400000\n",
      "40       WR     16          212.0  amon-ra st. brown0  13.250000\n",
      "43       WR     13          171.0       keenan allen0  13.153846\n",
      "    Position  Games  FantasyPoints         PlayerID   AvgFPPG\n",
      "104       TE     17          153.0     sam laporta0  9.000000\n",
      "105       TE     10           90.0    mark andrews0  9.000000\n",
      "111       TE     16          138.0   george kittle0  8.625000\n",
      "115       TE     15          126.0    travis kelce0  8.400000\n",
      "117       TE     15          124.0  t.j. hockenson0  8.266667\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a new DataFrame\n",
    "player_df = pd.read_csv('AvgFPPG_2022.csv')\n",
    "\n",
    "# Create a DataFrame for each position\n",
    "qb_df = player_df[player_df['Position'] == 'QB']\n",
    "rb_df = player_df[player_df['Position'] == 'RB']\n",
    "wr_df = player_df[player_df['Position'] == 'WR']\n",
    "te_df = player_df[player_df['Position'] == 'TE']\n",
    "\n",
    "# Display the first few rows of each position DataFrame\n",
    "print(qb_df.head())\n",
    "print(rb_df.head())\n",
    "print(wr_df.head())\n",
    "print(te_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data I think I will attempt the best draft possible for my league\n",
    "\n",
    "The best order for drafting is\n",
    "Round 1: RB\n",
    "Round 2: WR\n",
    "Round 3: RB or WR\n",
    "Round 4: RB or WR\n",
    "Round 5: RB or WR (or really good TE)\n",
    "Round 6: RB or WR (or really good TE)\n",
    "Round 7: RB, WR, or TE\n",
    "Round 8: QB, RB, or WR\n",
    "Round 9: QB, RB, or WR (or really good TE)\n",
    "Round 10: QB, RB, WR or TE\n",
    "Round 11: QB, RB, WR or TE\n",
    "Round 12: QB, RB, WR or TE\n",
    "Round 13: K\n",
    "Round 14: K or D/ST\n",
    "Round 15: K or D/ST\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
