{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "name": "GATv2_GCN_NBA_Reproduction.ipynb",
   "provenance": [],
   "gpuType": "A100",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GATv2-GCN NBA Player Performance Prediction\n\n## Full Reproduction on Google Colab (A100)\n\n> **Paper:** *Predicting NBA Player Performance via Graph Attention Networks with Temporal Convolutions* (Luo & Krishnamurthy 2023)\n\n\n\nThis notebook implements the complete pipeline end-to-end:\n\n1. **Environment setup** \u2014 install all dependencies on Colab\n\n2. **Mount Google Drive** \u2014 load helper scripts and save all outputs\n\n3. **Data acquisition** \u2014 scrape NBA box-scores via `nba_api` (2022-23 through 2025-26)\n\n4. **Preprocessing** \u2014 forward-fill, Z-score normalise, build graph sequence\n\n5. **Model definition** \u2014 GATv2Conv + Temporal Conv2D architecture (17-D input \u2192 6-stat output)\n\n6. **Training** \u2014 Adam, MSE, 50/25/25 chronological split, 300 epochs\n\n7. **Baseline comparison** \u2014 Na\u00efve, TCN-only, ASTGCN\n\n8. **Evaluation & visualisation** \u2014 RMSE, MAE, MAPE, CORR + rich figures\n\n9. **Case study** \u2014 Underdog Fantasy prop-line pick'em replay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 \u00b7 Runtime Check\nMake sure you have selected **A100** (or at least T4) under *Runtime \u2192 Change runtime type*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\ngpu = subprocess.run(['nvidia-smi','--query-gpu=name','--format=csv,noheader'],\n                    capture_output=True, text=True).stdout.strip()\nprint('GPU:', gpu)\nprint('Python:', sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 \u00b7 Install Dependencies\nColab ships with PyTorch; we only need to add `torch-geometric` and `nba-api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install extra packages (takes ~60 s on first run)\n!pip install -q torch-geometric nba-api\n# Confirm versions\nimport torch, torch_geometric\nprint('PyTorch:', torch.__version__)\nprint('PyG:    ', torch_geometric.__version__)\nprint('CUDA:   ', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 \u00b7 Mount Google Drive\n\nUpload the `knowball/networks/reproduction/` and `knowball/networks/NBA-GNN-prediction/` folders to your Drive.\n\nExpected layout inside Drive:\n\n```\n\nMyDrive/\n\n  knowball/\n\n    NBA-GNN-prediction/\n\n      gatv2tcn.py\n\n      tcn.py            \u2190 stub included in the upload folder\n\n      player_id2name.pkl\n\n      player_id2team.pkl\n\n      player_id2position.pkl\n\n      data/\n\n        X_seq.pkl\n\n        G_seq.pkl\n\n    reproduction/\n\n      01_data_pipeline.py\n\n      02_train.py\n\n      03_baselines_and_analysis.py\n\n```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\ndrive.mount('/content/drive')\n\nimport sys, os\nDRIVE_ROOT = '/content/drive/MyDrive/knowball'\nREPO_ROOT  = f'{DRIVE_ROOT}/NBA-GNN-prediction'\nREPRO_ROOT = f'{DRIVE_ROOT}/reproduction'\nsys.path.insert(0, REPO_ROOT)\nsys.path.insert(0, REPRO_ROOT)\n\n# Output directories (written back to Drive so nothing is lost if runtime disconnects)\nMODEL_DIR  = f'{DRIVE_ROOT}/outputs/model'\nFIG_DIR    = f'{DRIVE_ROOT}/outputs/figures'\nDATA_DIR   = f'{DRIVE_ROOT}/outputs/data'\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(FIG_DIR,   exist_ok=True)\nos.makedirs(DATA_DIR,  exist_ok=True)\nprint(\"Drive mounted. Paths ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 \u00b7 Shared Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, itertools, json, logging, pickle, time, warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport pandas as pd\nimport networkx as nx\nfrom scipy import stats\nfrom sklearn import preprocessing\nfrom sklearn.metrics import (mean_squared_error, mean_absolute_error,\n                             mean_absolute_percentage_error)\nfrom numpy.lib.stride_tricks import sliding_window_view\n\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.autograd import Variable\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', DEVICE)\n\n# \u2500\u2500 Feature / prediction constants \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFEATURE_COLS    = ['PTS','AST','REB','TO','STL','BLK','PLUS_MINUS',\n                   'TCHS','PASS','DIST','PACE','USG_PCT','TS_PCT']\nPREDICTION_COLS = ['PTS','AST','REB','TO','STL','BLK']\nPRED_INDICES    = [FEATURE_COLS.index(c) for c in PREDICTION_COLS]\nMIN_MINUTES     = 10.0\nSEQ_LENGTH      = 10\nOFFSET          = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 \u00b7 Data Acquisition\n\nWe call the `nba_api` for traditional, advanced, and player-tracking box-scores across four seasons.\n\n**Time estimate on Colab:** ~2-4 hours (API rate limits, ~0.7 s/request \u00d7 3 calls/game \u00d7 ~1 200 games).\n\nIf you already ran this and saved `raw_boxscores.parquet` to Drive, the cell will reload it instantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import (\n    leaguegamefinder, boxscoretraditionalv2,\n    boxscoreadvancedv2, boxscoreplayertrackv3,\n)\nfrom datetime import date\n\nSEASONS = [\n    ('2022-23', '2022-10-18', '2023-04-09'),\n    ('2023-24', '2023-10-24', '2024-04-14'),\n    ('2024-25', '2024-10-22', '2025-04-13'),\n    ('2025-26', '2025-10-28', str(date.today())),\n]\nAPI_DELAY   = 0.7\nTRAD_COLS   = ['GAME_ID','PLAYER_ID','PLAYER_NAME','TEAM_ID','TEAM_ABBREVIATION',\n               'MIN','PTS','AST','REB','TO','STL','BLK','PLUS_MINUS']\nADV_COLS    = ['GAME_ID','PLAYER_ID','PACE','USG_PCT','TS_PCT']\nTRACK_COLS  = ['GAME_ID','PLAYER_ID','DIST','TCHS','PASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_min(m):\n    if pd.isna(m): return 0.0\n    if isinstance(m, str) and ':' in m:\n        p = m.split(':'); return float(p[0]) + float(p[1])/60\n    return float(m)\n\ndef get_game_ids(season, d_from, d_to):\n    gf = leaguegamefinder.LeagueGameFinder(\n        season_nullable=season, season_type_nullable='Regular Season',\n        date_from_nullable=d_from, date_to_nullable=d_to, league_id_nullable='00')\n    df = gf.get_data_frames()[0]\n    return sorted(df['GAME_ID'].drop_duplicates().tolist())\n\ndef fetch_game(game_id):\n    try:\n        time.sleep(API_DELAY)\n        dt = boxscoretraditionalv2.BoxScoreTraditionalV2(game_id=game_id).get_data_frames()[0]\n        time.sleep(API_DELAY)\n        da = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=game_id).get_data_frames()[0]\n        time.sleep(API_DELAY)\n        dk = boxscoreplayertrackv3.BoxScorePlayerTrackV3(game_id=game_id).get_data_frames()[0]\n        dk.columns = dk.columns.str.upper()\n        for want, variants in [('DIST',['DIST','DISTANCE']),('TCHS',['TCHS','TOUCHES']),('PASS',['PASS','PASSES'])]:\n            for v in variants:\n                if v in dk.columns: dk = dk.rename(columns={v: want}); break\n        avt = [c for c in TRAD_COLS  if c in dt.columns]\n        ava = [c for c in ADV_COLS   if c in da.columns]\n        avk = ['GAME_ID','PLAYER_ID'] + [c for c in ['DIST','TCHS','PASS'] if c in dk.columns]\n        df  = dt[avt].merge(da[ava], on=['GAME_ID','PLAYER_ID'], how='left')\n        df  = df.merge(dk[avk],     on=['GAME_ID','PLAYER_ID'], how='left')\n        df['MIN'] = df['MIN'].apply(parse_min)\n        return df[df['MIN'] >= MIN_MINUTES]\n    except Exception as e:\n        print(f'  skip {game_id}: {e}'); return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = f'{DATA_DIR}/raw_boxscores.parquet'\n\nif os.path.exists(RAW_PATH):\n    print('Loading cached raw data\u2026')\n    raw_df = pd.read_parquet(RAW_PATH)\nelse:\n    print('Starting data acquisition (this will take a few hours)\u2026')\n    frames = []\n    for season, d_from, d_to in SEASONS:\n        print(f'\\nSeason {season}')\n        gids = get_game_ids(season, d_from, d_to)\n        print(f'  {len(gids)} games')\n        for k, gid in enumerate(gids):\n            if k % 50 == 0: print(f'  [{k}/{len(gids)}]')\n            df = fetch_game(gid)\n            if df is not None and len(df):\n                df['SEASON'] = season\n                frames.append(df)\n    raw_df = pd.concat(frames, ignore_index=True)\n    raw_df.to_parquet(RAW_PATH, index=False)\n    print(f'Saved {len(raw_df):,} rows \u2192 {RAW_PATH}')\n\nprint(f'Total player-game rows: {len(raw_df):,}')\nraw_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 \u00b7 Preprocessing & Graph Construction\n\n- Parse game dates from `GAME_ID` (format `002YYYYMMDD`)\n\n- Forward-fill zeros (players who sat out carry their last stats)\n\n- Z-score normalise each feature\n\n- Build an undirected graph per game-day: edge \u2194 two players competed in the same game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zeros_with_last(seq):\n    seq_ff = np.zeros_like(seq)\n    for i in range(seq.shape[1]):\n        arr = seq[:, i]\n        prev = np.arange(len(arr))\n        prev[arr == 0] = 0\n        prev = np.maximum.accumulate(prev)\n        seq_ff[:, i] = arr[prev]\n    return seq_ff\n\ndef preprocess(df):\n    for c in FEATURE_COLS:\n        if c not in df.columns: df[c] = 0.0\n    if 'GAME_DATE' not in df.columns:\n        df['GAME_DATE'] = pd.to_datetime(\n            df['GAME_ID'].astype(str).str[3:11], format='%Y%m%d', errors='coerce')\n    df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n    df = df.sort_values('GAME_DATE')\n\n    player_ids  = sorted(df['PLAYER_ID'].unique())\n    player_index = {p: i for i, p in enumerate(player_ids)}\n    N = len(player_ids)\n    game_dates  = sorted(df['GAME_DATE'].dt.date.unique())\n    D = len(game_dates)\n    print(f'Players: {N}   Game-days: {D}')\n\n    X_raw = np.zeros((D, N, len(FEATURE_COLS)), dtype=np.float32)\n    G_raw = []\n    for d, gdate in enumerate(game_dates):\n        day = df[df['GAME_DATE'].dt.date == gdate]\n        G = nx.Graph(); G.add_nodes_from(player_ids)\n        for gid, grp in day.groupby('GAME_ID'):\n            active = grp['PLAYER_ID'].tolist()\n            for pid in active:\n                if pid in player_index:\n                    row = grp[grp['PLAYER_ID']==pid].iloc[0]\n                    X_raw[d, player_index[pid]] = [float(row.get(c,0) or 0) for c in FEATURE_COLS]\n            for pA, pB in itertools.combinations(active, 2):\n                if pA in player_index and pB in player_index: G.add_edge(pA, pB)\n        G_raw.append(G)\n\n    X_ff = np.zeros_like(X_raw)\n    for p in range(N):\n        X_ff[:, p, :] = fill_zeros_with_last(X_raw[:, p, :])\n    mu = X_ff.mean(axis=(0,1), keepdims=True)\n    sd = X_ff.std(axis=(0,1),  keepdims=True) + 1e-8\n    X_norm = (X_ff - mu) / sd\n    return X_norm, G_raw, [str(d) for d in game_dates], player_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PKL = f'{DATA_DIR}/X_seq.pkl'\nG_PKL = f'{DATA_DIR}/G_seq.pkl'\nP_PKL = f'{DATA_DIR}/player_ids.pkl'\n\nif os.path.exists(X_PKL):\n    print('Loading cached tensors\u2026')\n    X_seq      = pickle.load(open(X_PKL,'rb'))\n    G_seq      = pickle.load(open(G_PKL,'rb'))\n    player_ids = pickle.load(open(P_PKL,'rb'))\nelse:\n    print('Building tensors\u2026')\n    X_seq, G_seq, game_dates, player_ids = preprocess(raw_df)\n    pickle.dump(X_seq,      open(X_PKL,'wb'))\n    pickle.dump(G_seq,      open(G_PKL,'wb'))\n    pickle.dump(player_ids, open(P_PKL,'wb'))\n    print('Saved.')\nprint('X_seq shape:', X_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 \u00b7 Team & Position Embeddings\n\nThe model takes a 17-D input per player per time-step:\n\n- 13 normalised statistics\n\n- 2-D projected team one-hot\n\n- 2-D projected position one-hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load from Drive pkl files (original repo), else build from raw_df\ndef build_embeddings(player_ids, raw_df):\n    N = len(player_ids)\n    pid_set = set(player_ids)\n\n    # Team: most common team per player, then label-encode \u2192 one-hot\n    pid2team_str = {}\n    for pid, grp in raw_df.groupby('PLAYER_ID'):\n        if pid in pid_set:\n            pid2team_str[pid] = grp['TEAM_ABBREVIATION'].mode()[0]\n    teams = sorted(set(pid2team_str.values()))\n    team2idx = {t:i for i,t in enumerate(teams)}\n    n_teams  = len(teams)\n    team_oh  = np.zeros((N, n_teams), dtype=np.float32)\n    for idx, pid in enumerate(player_ids):\n        team_oh[idx, team2idx.get(pid2team_str.get(pid,''), 0)] = 1.0\n\n    # Position: query nba_api static roster\n    try:\n        from nba_api.stats.static import players as nba_pl\n        static = {p['id']:p for p in nba_pl.get_players()}\n        pos_map = {'G':[0,1,0],'F':[1,0,0],'C':[0,0,1],'F-G':[1,1,0],'F-C':[1,0,1]}\n        def enc_pos(pid):\n            info = static.get(pid,{})\n            key  = (info.get('position','') or '').replace(' ','-')[:3]\n            return pos_map.get(key, [0,0,0])\n    except Exception:\n        enc_pos = lambda pid: [0,0,0]\n    pos_arr = np.array([enc_pos(pid) for pid in player_ids], dtype=np.float32)\n    n_pos   = pos_arr.shape[1]\n    return team_oh, pos_arr, n_teams, n_pos\n\nteam_oh, pos_arr, n_teams, n_pos = build_embeddings(player_ids, raw_df)\nteam_tensor = torch.FloatTensor(team_oh).to(DEVICE)\npos_tensor  = torch.FloatTensor(pos_arr).to(DEVICE)\nprint(f'Team one-hot: {team_oh.shape}   Position: {pos_arr.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 \u00b7 Convert Graphs to Edge-Index Tensors\nPyTorch Geometric expects `edge_index` as a `(2, E)` LongTensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_to_edges(G_seq, player_ids):\n    nd = {pid:i for i,pid in enumerate(player_ids)}\n    out = []\n    for G in G_seq:\n        edges = list(G.edges())\n        if not edges:\n            n = len(player_ids)\n            out.append(torch.stack([torch.arange(n),torch.arange(n)]).long())\n        else:\n            s,d = zip(*edges)\n            s = [nd.get(x,0) for x in s]; d = [nd.get(x,0) for x in d]\n            out.append(torch.stack([\n                torch.LongTensor(s+d), torch.LongTensor(d+s)]).to(DEVICE))\n    return out\n\nG_edges = graphs_to_edges(G_seq, player_ids)\nprint(f'Built {len(G_edges)} edge tensors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 \u00b7 Sliding Windows & Train/Val/Test Split\n\nFollowing the paper: **50 % train / 25 % val / 25 % test** (strictly chronological).\n\nA window of `SEQ_LENGTH=10` game-days predicts the next day's stats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.zeros_like(X_seq)\nfor i in range(X_seq.shape[1]):\n    Xs[:, i, :] = fill_zeros_with_last(X_seq[:, i, :])\n\nX_in  = sliding_window_view(Xs[:-OFFSET],      SEQ_LENGTH, axis=0)  # (T, N, F, 10)\nX_out = Xs[SEQ_LENGTH + OFFSET - 1:]                                  # (T, N, F)\nG_in  = [G_edges[t:t+SEQ_LENGTH] for t in range(len(G_edges)-SEQ_LENGTH-OFFSET+1)]\nG_out = G_edges[SEQ_LENGTH+OFFSET-1:]\n\nX_in  = torch.FloatTensor(np.array(X_in))\nX_out = torch.FloatTensor(np.array(X_out))\n\nT  = len(G_in)\nt1 = int(T * 0.50)\nt2 = int(T * 0.75)\nprint(f'Total windows: {T}  \u2192  train:{t1}  val:{t2-t1}  test:{T-t2}')\n\nX_tr, y_tr, G_tr = X_in[:t1], X_out[:t1], G_in[:t1]\nX_va, y_va, G_va = X_in[t1:t2], X_out[t1:t2], G_in[t1:t2]\nX_te, y_te, G_te = X_in[t2:],  X_out[t2:],  G_in[t2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 \u00b7 Model Definition \u2014 GATv2-TCN\n\nWe import `GATv2TCN` from the repo's `gatv2tcn.py`. The architecture:\n\n| Layer | Details |\n\n|---|---|\n\n| Input | 17-D per player (13 stats + 2 team emb + 2 pos emb) |\n\n| **GATv2Conv** | `in=17, out=32, heads=4` \u2192 128-D spatial rep |\n\n| **Temporal Conv2D** | `(128\u219264)`, kernel `(1,1)` |\n\n| Residual Conv2D | `(17\u219264)`, adds skip connection |\n\n| LayerNorm + ReLU | stabilise gradients |\n\n| Final Conv2D | maps `seq_len` \u2192 6-stat prediction |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gatv2tcn import GATv2TCN\n\nmodel_in = len(FEATURE_COLS) + 2 + 2  # 17\n\nteam_emb = nn.Linear(n_teams, 2).to(DEVICE)\npos_emb  = nn.Linear(n_pos, 2).to(DEVICE)\nmodel    = GATv2TCN(\n    in_channels=model_in, out_channels=6,\n    len_input=SEQ_LENGTH, len_output=1,\n    temporal_filter=64, out_gatv2conv=32,\n    dropout_tcn=0.25, dropout_gatv2conv=0.5, head_gatv2conv=4,\n).to(DEVICE)\n\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'Trainable parameters: {total_params:,}')\nprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 \u00b7 Training\n\n- **Optimiser:** Adam, `lr=0.001`, `weight_decay=0.001`\n\n- **Loss:** MSE (only over players who actually played that day)\n\n- **Epochs:** 300 | **Mini-batch:** 20 randomly sampled training days/epoch\n\n- Best checkpoint saved to Drive on every validation improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS     = 300\nBATCH_SIZE = 20\nLR         = 1e-3\nWD         = 1e-3\n\nparams = (list(model.parameters()) +\n          list(team_emb.parameters()) +\n          list(pos_emb.parameters()))\noptimizer  = torch.optim.Adam(params, lr=LR, weight_decay=WD)\nscheduler  = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\ntrain_hist, val_hist = [], []\nbest_val   = float('inf')\nbest_epoch = -1\n\nfor epoch in range(EPOCHS):\n    # \u2500\u2500 train \u2500\u2500\n    model.train(); team_emb.train(); pos_emb.train()\n    tv = team_emb(team_tensor); pv = pos_emb(pos_tensor)\n    t_loss = torch.tensor(0.0, device=DEVICE)\n    idx = np.random.choice(len(X_tr), size=min(BATCH_SIZE,len(X_tr)), replace=False)\n    for i in idx:\n        Xl = [torch.cat([X_tr[i,:,:,t].to(DEVICE), tv, pv], 1) for t in range(SEQ_LENGTH)]\n        x  = torch.stack(Xl,-1)[None,...]\n        p  = model(x, G_tr[i])[0]\n        t_loss = t_loss + F.mse_loss(p, y_tr[i,:,PRED_INDICES].to(DEVICE))\n    t_loss.backward(); optimizer.step(); optimizer.zero_grad(); scheduler.step()\n\n    # \u2500\u2500 validate \u2500\u2500\n    model.eval(); team_emb.eval(); pos_emb.eval()\n    with torch.no_grad():\n        tv2=team_emb(team_tensor); pv2=pos_emb(pos_tensor)\n        v_loss = 0.0\n        for i in range(len(X_va)):\n            Xl = [torch.cat([X_va[i,:,:,t].to(DEVICE), tv2, pv2], 1) for t in range(SEQ_LENGTH)]\n            x  = torch.stack(Xl,-1)[None,...]\n            p  = model(x, G_va[i])[0]\n            v_loss += F.mse_loss(p, y_va[i,:,PRED_INDICES].to(DEVICE)).item()\n\n    train_hist.append(t_loss.item()); val_hist.append(v_loss)\n    if v_loss < best_val:\n        best_val=v_loss; best_epoch=epoch\n        torch.save(model.state_dict(),    f'{MODEL_DIR}/model.pth')\n        torch.save(team_emb.state_dict(), f'{MODEL_DIR}/team_emb.pth')\n        torch.save(pos_emb.state_dict(),  f'{MODEL_DIR}/pos_emb.pth')\n        print(f'  \u2193 val {v_loss:.4f} (epoch {epoch})')\n    if epoch % 50 == 0:\n        print(f'Epoch {epoch:03d} | train {t_loss.item():.4f} | val {v_loss:.4f}')\n\nprint(f'\\nBest val loss: {best_val:.4f} at epoch {best_epoch}')\nnp.save(f'{MODEL_DIR}/train_hist.npy', np.array(train_hist))\nnp.save(f'{MODEL_DIR}/val_hist.npy',   np.array(val_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 \u00b7 Test Set Evaluation\nLoad the best checkpoint and compute RMSE, MAE, MAPE, and Fisher-z CORR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{MODEL_DIR}/model.pth', map_location=DEVICE))\nteam_emb.load_state_dict(torch.load(f'{MODEL_DIR}/team_emb.pth', map_location=DEVICE))\npos_emb.load_state_dict(torch.load(f'{MODEL_DIR}/pos_emb.pth', map_location=DEVICE))\nmodel.eval(); team_emb.eval(); pos_emb.eval()\n\nall_preds, all_trues = [], []\nwith torch.no_grad():\n    tv=team_emb(team_tensor); pv=pos_emb(pos_tensor)\n    for i in range(len(X_te)):\n        Xl=[torch.cat([X_te[i,:,:,t].to(DEVICE),tv,pv],1) for t in range(SEQ_LENGTH)]\n        x =torch.stack(Xl,-1)[None,...]\n        p =model(x, G_te[i])[0].cpu().numpy()\n        t2=y_te[i,:,PRED_INDICES].numpy()\n        all_preds.append(p); all_trues.append(t2)\n\nAP=np.concatenate(all_preds); AT=np.concatenate(all_trues)\nrmse_v = mean_squared_error(AT, AP, squared=False)\nmae_v  = mean_absolute_error(AT, AP)\nmape_v = mean_absolute_percentage_error(AT, AP)\ncorr_z = []\nfor mi in range(6):\n    r=np.corrcoef(AP[:,mi],AT[:,mi])[0,1]\n    if not np.isnan(r) and abs(r)<1-1e-7: corr_z.append(np.arctanh(r))\ncorr_v = np.tanh(np.mean(corr_z)) if corr_z else float('nan')\n\nrepro_metrics = {'RMSE':float(rmse_v),'MAE':float(mae_v),\n                 'MAPE':float(mape_v),'CORR':float(corr_v)}\nprint('\u2500\u2500 Test Metrics \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500')\nfor k,v in repro_metrics.items(): print(f'  {k}: {v:.4f}')\nwith open(f'{MODEL_DIR}/test_metrics.json','w') as f: json.dump(repro_metrics,f,indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 \u00b7 Visualisations\nAll figures are saved to your Drive. Run sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12a \u00b7 Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\nax.plot(train_hist, label='Train Loss', color='#5b8fc7', lw=2)\nax.plot(val_hist,   label='Val Loss',   color='#e07b54', lw=2)\nax.axvline(best_epoch, color='gray', ls='--', lw=1.5, label=f'Best ({best_epoch})')\nax.set_xlabel('Epoch'); ax.set_ylabel('MSE Loss')\nax.set_title('GATv2-TCN Learning Curves', fontweight='bold')\nax.legend(); ax.grid(alpha=0.25)\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/loss_curves.png', dpi=150)\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12b \u00b7 Model Benchmark Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER = {\n    'N-BEATS':     {'RMSE':5.112,'MAE':4.552,'MAPE':3.701,'CORR':0.366},\n    'DeepVAR':     {'RMSE':2.896,'MAE':2.151,'MAPE':1.754,'CORR':0.396},\n    'TCN':         {'RMSE':2.414,'MAE':1.780,'MAPE':0.551,'CORR':0.418},\n    'ASTGCN':      {'RMSE':2.293,'MAE':1.699,'MAPE':0.455,'CORR':0.453},\n    'GATv2 (Paper)':{'RMSE':2.222,'MAE':1.642,'MAPE':0.513,'CORR':0.508},\n    'GATv2 (Repro)': repro_metrics,\n}\nCOLORS = ['#e07b54','#5b8fc7','#70b472','#c07ec9','#f0c040','#e84393']\nmets   = ['RMSE','MAE','CORR']\nfig, axes = plt.subplots(1,3,figsize=(16,5))\nfor ax, met in zip(axes, mets):\n    models = list(PAPER.keys())\n    vals   = [PAPER[m][met] for m in models]\n    bars   = ax.bar(range(len(models)), vals, color=COLORS, edgecolor='white', width=0.65)\n    for b,v in zip(bars,vals):\n        ax.text(b.get_x()+b.get_width()/2, b.get_height()+0.01*max(vals),\n                f'{v:.3f}', ha='center', fontsize=8.5, fontweight='bold')\n    ax.set_xticks(range(len(models)))\n    ax.set_xticklabels(models, rotation=35, ha='right', fontsize=9)\n    ax.set_title(met, fontweight='bold'); ax.grid(axis='y',alpha=0.2)\nplt.suptitle('Model Benchmark Comparison', fontweight='bold')\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/model_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12c \u00b7 Predicted vs. Actual (per statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=['#5b8fc7','#e07b54','#70b472','#c07ec9','#f0c040','#e84393']\nfig, axes = plt.subplots(2,3,figsize=(15,9))\nfor i,(ax,stat) in enumerate(zip(axes.ravel(), PREDICTION_COLS)):\n    p,t = AP[:,i], AT[:,i]\n    ax.scatter(t, p, alpha=0.25, s=8, color=colors[i], rasterized=True)\n    lo,hi = min(t.min(),p.min()), max(t.max(),p.max())\n    ax.plot([lo,hi],[lo,hi],'k--',lw=1.5,alpha=0.6,label='Perfect')\n    m,b,r,*_ = stats.linregress(t,p)\n    xs=np.array([lo,hi]); ax.plot(xs,m*xs+b,'r-',lw=2,label=f'r={r:.3f}')\n    ax.set_title(f'{stat} | MAE={mean_absolute_error(t,p):.2f}', fontweight='bold')\n    ax.set_xlabel('Actual'); ax.set_ylabel('Predicted')\n    ax.legend(fontsize=8); ax.grid(alpha=0.15)\nplt.suptitle('GATv2-TCN: Predicted vs. Actual (Test Set)', fontweight='bold')\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/pred_vs_actual.png', dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12d \u00b7 Per-Statistic Error Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_s  = np.abs(AP-AT).mean(0)\nrmse_s = np.sqrt(((AP-AT)**2).mean(0))\ncorr_s = [np.corrcoef(AP[:,i],AT[:,i])[0,1] for i in range(6)]\nx=np.arange(6); w=0.28\nfig,ax=plt.subplots(figsize=(12,5))\nfor off, vals, lbl, col in [(-w,mae_s,'MAE','#5b8fc7'),(0,rmse_s,'RMSE','#e07b54'),(w,corr_s,'CORR','#70b472')]:\n    bars=ax.bar(x+off, vals, w, label=lbl, color=col, edgecolor='white')\n    for bar in bars:\n        ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+0.01,\n                f'{bar.get_height():.2f}', ha='center', fontsize=8)\nax.set_xticks(x); ax.set_xticklabels(PREDICTION_COLS, fontsize=12)\nax.set_title('Per-Statistic Error Metrics (Test Set)', fontweight='bold')\nax.legend(); ax.grid(axis='y',alpha=0.2)\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/per_stat_errors.png', dpi=150)\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12e \u00b7 Residual Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = AP - AT\nfig,axes=plt.subplots(2,3,figsize=(15,8))\nfor i,(ax,stat) in enumerate(zip(axes.ravel(),PREDICTION_COLS)):\n    r=res[:,i]\n    ax.hist(r, bins=60, color=colors[i], edgecolor='white', alpha=0.85, density=True)\n    xs=np.linspace(r.min(),r.max(),300)\n    ax.plot(xs, stats.norm.pdf(xs,r.mean(),r.std()), 'k-', lw=2)\n    ax.axvline(0,          color='red',    ls='--', lw=1.5)\n    ax.axvline(r.mean(),   color='orange', ls='-',  lw=1.5, label=f'\u03bc={r.mean():.2f}')\n    ax.set_title(stat, fontweight='bold')\n    ax.legend(fontsize=8); ax.grid(axis='y',alpha=0.2)\nplt.suptitle('Residual Error Distributions', fontweight='bold')\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/residuals.png', dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12f \u00b7 Correlation Heatmap (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT_LBL=['PTS','AST','REB','TO','STL','BLK','\u00b1','TCHS','PASS','DIST','PACE','USG%','TS%']\nn=X_seq.shape[-1]\nflat=X_seq.reshape(-1,n)\nflat=flat[(flat!=0).any(1)]\ncorr_mat=np.corrcoef(flat.T)\nfig,ax=plt.subplots(figsize=(9,7))\nim=ax.imshow(corr_mat, cmap='RdBu_r', vmin=-1, vmax=1)\nax.set_xticks(range(n)); ax.set_xticklabels(STAT_LBL[:n],rotation=45,ha='right')\nax.set_yticks(range(n)); ax.set_yticklabels(STAT_LBL[:n])\nfor i in range(n):\n    for j in range(n):\n        ax.text(j,i,f'{corr_mat[i,j]:.2f}',ha='center',va='center',fontsize=7,\n               color='white' if abs(corr_mat[i,j])>0.5 else 'black')\nplt.colorbar(im,ax=ax,shrink=0.8,label='Pearson r')\nax.set_title('Feature Correlation Matrix', fontweight='bold')\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/correlation_heatmap.png', dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12g \u00b7 Graph Topology Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise one game-day graph (mid-dataset)\nid2name = {k:v for k,v in zip(player_ids, [str(p) for p in player_ids])}\ntry:\n    id2name_pkl = f'{REPO_ROOT}/player_id2name.pkl'\n    if os.path.exists(id2name_pkl):\n        id2name = pickle.load(open(id2name_pkl,'rb'))\nexcept Exception: pass\n\nG_sample = G_seq[len(G_seq)//2]\nactive   = [n for n in G_sample.nodes() if G_sample.degree(n)>0][:60]\nsubG     = G_sample.subgraph(active)\ncomps    = list(nx.connected_components(subG))\ncmap     = plt.cm.get_cmap('tab20', len(comps))\nnc = {}\nfor k,comp in enumerate(comps):\n    for n in comp: nc[n]=cmap(k%20)\n\nfig,ax=plt.subplots(figsize=(13,10))\npos=nx.kamada_kawai_layout(subG)\nlabels={n:str(id2name.get(n,n))[:10] for n in subG.nodes()}\nnx.draw_networkx_nodes(subG,pos,ax=ax,node_color=[nc.get(n,'#ccc') for n in subG.nodes()],\n                       node_size=250,alpha=0.93,linewidths=1.3,edgecolors='white')\nnx.draw_networkx_edges(subG,pos,ax=ax,alpha=0.3,edge_color='#888',width=1.2)\nnx.draw_networkx_labels(subG,pos,labels=labels,ax=ax,font_size=6.5)\nax.set_title('Game-Day Graph Topology (colours = game clusters)', fontweight='bold')\nax.axis('off'); plt.tight_layout()\nplt.savefig(f'{FIG_DIR}/graph_topology.png', dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12h \u00b7 Performance Radar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r = {**PAPER, 'GATv2 (Repro)': repro_metrics}\ndef to_radar(r): return {'1/RMSE':1/max(r['RMSE'],1e-6),'1/MAE':1/max(r['MAE'],1e-6),\n                          '1/MAPE':1/max(r['MAPE'],1e-6),'CORR':r['CORR']}\nnormed={m:to_radar(v) for m,v in all_r.items()}\ncats=list(next(iter(normed.values())).keys())\nangles=np.linspace(0,2*np.pi,len(cats),endpoint=False).tolist()+[0]\nRCOLS=['#e07b54','#5b8fc7','#70b472','#c07ec9','#f0c040','#e84393']\nfig,ax=plt.subplots(figsize=(8,8),subplot_kw={'polar':True})\nfor (model,m),col in zip(normed.items(),RCOLS):\n    vals=list(m.values())+[list(m.values())[0]]\n    ax.plot(angles,vals,lw=2.5,color=col,label=model)\n    ax.fill(angles,vals,alpha=0.07,color=col)\nax.set_xticks(angles[:-1]); ax.set_xticklabels(cats,fontsize=12)\nax.set_yticklabels([])\nax.set_title('Performance Radar (higher=better on all axes)',fontweight='bold',pad=25)\nax.legend(loc='upper right',bbox_to_anchor=(1.45,1.1),fontsize=9)\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/radar.png', dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12i \u00b7 Population-Average PTS Forecast Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_te=len(all_preds)\nmean_p=[all_preds[i][:,0].mean() for i in range(T_te)]\nmean_t=[all_trues[i][:,0].mean() for i in range(T_te)]\nstd_p =[all_preds[i][:,0].std()  for i in range(T_te)]\nx=np.arange(T_te)\nfig,ax=plt.subplots(figsize=(14,4.5))\nax.plot(x,mean_t,color='#e07b54',lw=2.5,ls='--',label='Actual PTS')\nax.plot(x,mean_p,color='#5b8fc7',lw=2.5,label='Predicted PTS')\nax.fill_between(x,np.array(mean_p)-np.array(std_p),\n                  np.array(mean_p)+np.array(std_p),alpha=0.18,color='#5b8fc7',label='\u00b11\u03c3')\nax.set_xlabel('Test-Set Game-Day Index'); ax.set_ylabel('PTS (Z-Normalised)')\nax.set_title('Population-Average PTS Forecast vs. Actuals',fontweight='bold')\nax.legend(); ax.grid(axis='y',alpha=0.2)\nplt.tight_layout()\nplt.savefig(f'{FIG_DIR}/pts_trend.png', dpi=150)\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 \u00b7 Case Study \u2014 Underdog Fantasy Prop Pick'em Replay\n\nThe paper evaluated the trained model on the January 20 2023 slate.\n\nA pick is **correct** if the model's prediction and the true outcome are on the **same side** of the prop line.\n\nThe paper achieved **35/59 = 59.3 %**, well above the 52.4 % breakeven for -110 juice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original X_seq / G_seq from the repo (covers the 2022-23 season only)\nORIG_X = f'{REPO_ROOT}/data/X_seq.pkl'\nORIG_G = f'{REPO_ROOT}/data/G_seq.pkl'\nORIG_N = f'{REPO_ROOT}/player_id2name.pkl'\n\nif all(os.path.exists(p) for p in [ORIG_X,ORIG_G,ORIG_N]):\n    ox = pickle.load(open(ORIG_X,'rb'))\n    og = pickle.load(open(ORIG_G,'rb'))\n    on = pickle.load(open(ORIG_N,'rb'))\n\n    og_edges = graphs_to_edges(og, list(on.keys()))\n    Xs2=np.zeros_like(ox)\n    for i in range(ox.shape[1]): Xs2[:,i,:]=fill_zeros_with_last(ox[:,i,:])\n\n    # Use last 10 days as input window \u2192 predict day 91\n    with torch.no_grad():\n        tv=team_emb(team_tensor); pv=pos_emb(pos_tensor)\n        Xl=[torch.cat([torch.FloatTensor(Xs2[-11+t]).to(DEVICE), tv, pv],1)\n            for t in range(SEQ_LENGTH)]\n        x=torch.stack(Xl,-1)[None,...]\n        preds_jan20 = model(x, og_edges[-11:-1])[0].cpu().numpy()\n\n    TODAY_PROPS = {\n        'CJ McCollum':         {'PTS':25.5},\n        'Jonas Valanciunas':   {'PTS':19.0,'REB':11.5},\n        'Paolo Banchero':      {'PTS':9.5,'REB':6.0},\n        'Luka Doncic':         {'PTS':34.5,'REB':10.5,'AST':9.0},\n        'Jimmy Butler':        {'PTS':20.5,'REB':6.0,'STL':1.5},\n        'Bam Adebayo':         {'PTS':21.5,'REB':10.5},\n        'Darius Garland':      {'PTS':25.5,'AST':8.5},\n        'Evan Mobley':         {'PTS':16.5,'REB':9.0},\n    }\n    pid_list   = list(on.keys())\n    name_list  = list(on.values())\n    correct=0; total=0; rows=[]\n    for player,props in TODAY_PROPS.items():\n        if player not in name_list: continue\n        pidx = name_list.index(player)\n        true_row = ox[-1][pidx] if pidx < ox.shape[1] else None\n        for stat, line in props.items():\n            if stat not in PREDICTION_COLS: continue\n            si = PREDICTION_COLS.index(stat)\n            pred_val = float(preds_jan20[pidx, si])\n            true_val = float(ox[-1][pidx, si]) if true_row is not None else float('nan')\n            over_pred = pred_val > line\n            over_true = true_val > line\n            ok = over_pred == over_true\n            if not np.isnan(true_val):\n                correct += int(ok); total += 1\n            rows.append({'Player':player,'Stat':stat,'Line':line,\n                         'Predicted':round(pred_val,2),'Actual':round(true_val,2),\n                         'Correct':ok})\n    df_case = pd.DataFrame(rows)\n    print(f'Pick accuracy: {correct}/{total} = {100*correct/max(total,1):.1f}%')\n    display(df_case)\nelse:\n    print('Original repo data not found at expected Drive path \u2013 skipping case study.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 \u00b7 Final Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(PAPER).T.rename_axis('Model')\nsummary.loc['GATv2 (Repro)'] = pd.Series(repro_metrics)\nsummary = summary.round(3)\ndisplay(summary.style.background_gradient(cmap='RdYlGn_r', subset=['RMSE','MAE','MAPE'])\n                       .background_gradient(cmap='RdYlGn',  subset=['CORR']))\nsummary.to_csv(f'{MODEL_DIR}/summary_table.csv')\nprint('Saved summary table to Drive.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## \u2705 All Done!\n\nYour Drive `knowball/outputs/` folder now contains:\n\n- `model/model.pth` \u2014 best GATv2-TCN checkpoint\n\n- `model/test_metrics.json` \u2014 RMSE / MAE / MAPE / CORR\n\n- `model/train_hist.npy` + `val_hist.npy` \u2014 loss curves\n\n- `model/summary_table.csv` \u2014 full comparison table\n\n- `figures/*.png` \u2014 all publication-quality figures\n"
   ]
  }
 ]
}